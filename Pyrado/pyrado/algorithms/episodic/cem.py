# Copyright (c) 2020, Fabio Muratore, Honda Research Institute Europe GmbH, and
# Technical University of Darmstadt.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
# 3. Neither the name of Fabio Muratore, Honda Research Institute Europe GmbH,
#    or Technical University of Darmstadt, nor the names of its contributors may
#    be used to endorse or promote products derived from this software without
#    specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL FABIO MURATORE, HONDA RESEARCH INSTITUTE EUROPE GMBH,
# OR TECHNICAL UNIVERSITY OF DARMSTADT BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
# OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
# IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

import torch as to
from typing import Optional

import pyrado
from pyrado.algorithms.episodic.parameter_exploring import ParameterExploring
from pyrado.environments.base import Env
from pyrado.exploration.normal_noise import FullNormalNoise, DiagNormalNoise
from pyrado.exploration.stochastic_params import NormalParamNoise, SymmParamExplStrat
from pyrado.logger.step import StepLogger
from pyrado.policies.base import Policy
from pyrado.sampling.parameter_exploration_sampler import ParameterSamplingResult
from pyrado.utils.math import cov


class CEM(ParameterExploring):
    r"""
    Cross-Entropy Method (CEM)
    This implementation is basically Algorithm 3.3. in [1] with the addition of decreasing noise [2].
    CEM is closely related to PoWER. The most significant difference is that the importance sampels are not kept over
    iterations and that the covariance matrix is not scaled with the returns, thus allowing for negative returns.

    .. seealso::
        [1] P.T. de Boer, D.P. Kroese, S. Mannor, R.Y. Rubinstein, "A Tutorial on the Cross-Entropy Method",
        Annals OR, 2005
        [2] I. Szita, A. LÃ¶rnicz, "Learning Tetris Using the NoisyCross-Entropy Method", Neural Computation, 2006
    """

    name: str = "cem"

    def __init__(
        self,
        save_dir: pyrado.PathLike,
        env: Env,
        policy: Policy,
        max_iter: int,
        pop_size: Optional[int],
        num_init_states_per_domain: int,
        num_is_samples: int,
        expl_std_init: float,
        expl_std_min: float = 0.01,
        extra_expl_std_init: float = 0.0,
        extra_expl_decay_iter: int = 10,
        num_domains: Optional[int] = 1,
        full_cov: bool = False,
        symm_sampling: bool = False,
        num_workers: int = 4,
        logger: Optional[StepLogger] = None,
    ):
        r"""
        Constructor

        :param save_dir: directory to save the snapshots i.e. the results in
        :param env: the environment which the policy operates
        :param policy: policy to be updated
        :param max_iter: maximum number of iterations (i.e. policy updates) that this algorithm runs
        :param pop_size: number of solutions in the population
        :param num_init_states_per_domain: number of rollouts to cover the variance over initial states
        :param num_domains: number of rollouts due to the variance over domain parameters
        :param num_is_samples: number of samples (policy parameter sets & returns) for importance sampling,
                               indirectly specifies the performance quantile $1 - \rho$ [1]
        :param expl_std_init: initial standard deviation for the exploration strategy
        :param expl_std_min: minimal standard deviation for the exploration strategy
        :param extra_expl_std_init: additional standard deviation for the parameter exploration added to the diagonal
                                    entries of the covariance matirx, set to 0 to disable this functionality
        :param extra_expl_decay_iter: limit for the linear decay of the additional standard deviation, i.e. last
                                      iteration in which the additional exploration noise is applied
        :param full_cov: pass `True` to compute a full covariance matrix for sampling the next policy parameter values,
                         else a diagonal covariance is used
        :param symm_sampling: use an exploration strategy which samples symmetric populations
        :param num_workers: number of environments for parallel sampling
        :param logger: logger for every step of the algorithm, if `None` the default logger will be created
        """
        if not extra_expl_std_init >= 0:
            raise pyrado.ValueErr(given=extra_expl_std_init, ge_constraint="0")
        if not extra_expl_decay_iter > 0:
            raise pyrado.ValueErr(given=extra_expl_decay_iter, g_constraint="0")

        # Call ParameterExploring's constructor
        super().__init__(
            save_dir=save_dir,
            env=env,
            policy=policy,
            max_iter=max_iter,
            num_init_states_per_domain=num_init_states_per_domain,
            num_domains=num_domains,
            pop_size=pop_size,
            num_workers=num_workers,
            logger=logger,
        )

        if not num_is_samples <= pop_size:
            raise pyrado.ValueErr(given=num_is_samples, le_constraint=pop_size)
        self.num_is_samples = int(num_is_samples)

        # Explore using normal noise
        self._expl_strat = NormalParamNoise(
            self._policy.num_param,
            full_cov=full_cov,
            std_init=expl_std_init,
            std_min=expl_std_min,
            use_cuda=self._policy.device != "cpu",
        )
        if symm_sampling:
            # Exploration strategy based on symmetrical normally distributed noise
            if self.pop_size % 2 != 0:
                # Symmetric buffer needs to have an even number of samples
                self.pop_size += 1
            self._expl_strat = SymmParamExplStrat(self._expl_strat)

        # Optionally add additional entropy
        self.extra_expl_decay_iter = extra_expl_decay_iter
        if isinstance(self._expl_strat.noise, DiagNormalNoise):
            self.extra_expl_std_init = to.ones_like(self._policy.param_values) * extra_expl_std_init
        elif isinstance(self._expl_strat.noise, FullNormalNoise):
            self.extra_expl_std_init = to.eye(self._policy.num_param) * extra_expl_std_init
        else:
            raise pyrado.TypeErr(
                msg="Additional exploration entropy is only implemented for Gaussian distributions, "
                "i.e. DiagNormalNoise and FullNormalNoise"
            )
        self.extra_expl_std_init = self.extra_expl_std_init.to(device=self.policy.device)

    @to.no_grad()
    def update(self, param_results: ParameterSamplingResult, ret_avg_curr: float = None):
        # Average the return values over the rollouts
        rets_avg_ros = to.from_numpy(param_results.mean_returns).to(to.get_default_dtype())

        # Descending sort according to return values and the importance samples a.k.a. elites (see [1, p.12])
        idcs_dcs = to.argsort(rets_avg_ros, descending=True)
        idcs_dcs = idcs_dcs[: self.num_is_samples]
        rets_avg_is = rets_avg_ros[idcs_dcs]
        params_is = param_results.parameters[idcs_dcs, :]

        # Update the policy parameters from the mean importance samples
        self._policy.param_values = to.mean(params_is, dim=0)

        # Update the exploration covariance from the empirical variance of the importance samples
        if isinstance(self._expl_strat.noise, DiagNormalNoise):
            std_is = to.std(params_is, dim=0)
            extra_expl_std = self.extra_expl_std_init * max(
                1.0 - self._curr_iter / self.extra_expl_decay_iter, 0  # see [2, p.4]
            )
            self._expl_strat.noise.adapt(std=std_is + extra_expl_std)
        elif isinstance(self._expl_strat.noise, FullNormalNoise):
            cov_is = cov(params_is, data_along_rows=True)
            extra_expl_cov = to.pow(self.extra_expl_std_init, 2) * max(
                1.0 - self._curr_iter / self.extra_expl_decay_iter, 0  # see [2, p.4]
            )
            self._expl_strat.noise.adapt(cov=cov_is + extra_expl_cov)

        # Logging
        self.logger.add_value("median imp samp return", to.median(rets_avg_is), 4)
        self.logger.add_value("min imp samp return", to.min(rets_avg_is), 4)
        self.logger.add_value("min expl strat std", to.min(self._expl_strat.std), 4)
        self.logger.add_value("avg expl strat std", to.mean(self._expl_strat.std), 4)
        self.logger.add_value("max expl strat std", to.max(self._expl_strat.std), 4)
        self.logger.add_value("expl strat entropy", self._expl_strat.get_entropy(), 4)
